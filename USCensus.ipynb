{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/us census data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   age         workclass  fnlwgt  education      marital-status  \\\n0   39         State-gov   77516  Bachelors       Never-married   \n1   50  Self-emp-not-inc   83311  Bachelors  Married-civ-spouse   \n2   38           Private  215646    HS-grad            Divorced   \n3   53           Private  234721       11th  Married-civ-spouse   \n4   28           Private  338409  Bachelors  Married-civ-spouse   \n\n          occupation   relationship   race     sex  hours-per-week  \\\n0       Adm-clerical  Not-in-family  White    Male              40   \n1    Exec-managerial        Husband  White    Male              13   \n2  Handlers-cleaners  Not-in-family  White    Male              40   \n3  Handlers-cleaners        Husband  Black    Male              40   \n4     Prof-specialty           Wife  Black  Female              40   \n\n  native-country  capital income  \n0  United-States     2174  <=50K  \n1  United-States        0  <=50K  \n2  United-States        0  <=50K  \n3  United-States        0  <=50K  \n4           Cuba        0  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>capital</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>2174</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>0</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>0</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>0</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>0</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  count unique                 top   freq           mean  \\\nage             48842.0    NaN                 NaN    NaN      38.643585   \nworkclass         48842      7             Private  33906            NaN   \nfnlwgt          48842.0    NaN                 NaN    NaN  189664.134597   \neducation         48842     16             HS-grad  15784            NaN   \nmarital-status    48842      7  Married-civ-spouse  22379            NaN   \noccupation        48842     15      Prof-specialty   6172            NaN   \nrelationship      48842      6             Husband  19716            NaN   \nrace              48842      5               White  41762            NaN   \nsex               48842      2                Male  32650            NaN   \nhours-per-week  48842.0    NaN                 NaN    NaN      40.422382   \nnative-country    48842     42       United-States  43832            NaN   \ncapital         48842.0    NaN                 NaN    NaN     991.565313   \nincome            48842      2               <=50K  37155            NaN   \n\n                          std      min       25%       50%       75%  \\\nage                  13.71051     17.0      28.0      37.0      48.0   \nworkclass                 NaN      NaN       NaN       NaN       NaN   \nfnlwgt          105604.025423  12285.0  117550.5  178144.5  237642.0   \neducation                 NaN      NaN       NaN       NaN       NaN   \nmarital-status            NaN      NaN       NaN       NaN       NaN   \noccupation                NaN      NaN       NaN       NaN       NaN   \nrelationship              NaN      NaN       NaN       NaN       NaN   \nrace                      NaN      NaN       NaN       NaN       NaN   \nsex                       NaN      NaN       NaN       NaN       NaN   \nhours-per-week      12.391444      1.0      40.0      40.0      45.0   \nnative-country            NaN      NaN       NaN       NaN       NaN   \ncapital           7475.549906  -4356.0       0.0       0.0       0.0   \nincome                    NaN      NaN       NaN       NaN       NaN   \n\n                      max  \nage                  90.0  \nworkclass             NaN  \nfnlwgt          1490400.0  \neducation             NaN  \nmarital-status        NaN  \noccupation            NaN  \nrelationship          NaN  \nrace                  NaN  \nsex                   NaN  \nhours-per-week       99.0  \nnative-country        NaN  \ncapital           99999.0  \nincome                NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>48842.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.643585</td>\n      <td>13.71051</td>\n      <td>17.0</td>\n      <td>28.0</td>\n      <td>37.0</td>\n      <td>48.0</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>workclass</th>\n      <td>48842</td>\n      <td>7</td>\n      <td>Private</td>\n      <td>33906</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>fnlwgt</th>\n      <td>48842.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>189664.134597</td>\n      <td>105604.025423</td>\n      <td>12285.0</td>\n      <td>117550.5</td>\n      <td>178144.5</td>\n      <td>237642.0</td>\n      <td>1490400.0</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>48842</td>\n      <td>16</td>\n      <td>HS-grad</td>\n      <td>15784</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>marital-status</th>\n      <td>48842</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>22379</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>occupation</th>\n      <td>48842</td>\n      <td>15</td>\n      <td>Prof-specialty</td>\n      <td>6172</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>relationship</th>\n      <td>48842</td>\n      <td>6</td>\n      <td>Husband</td>\n      <td>19716</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>48842</td>\n      <td>5</td>\n      <td>White</td>\n      <td>41762</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>48842</td>\n      <td>2</td>\n      <td>Male</td>\n      <td>32650</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>hours-per-week</th>\n      <td>48842.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40.422382</td>\n      <td>12.391444</td>\n      <td>1.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>45.0</td>\n      <td>99.0</td>\n    </tr>\n    <tr>\n      <th>native-country</th>\n      <td>48842</td>\n      <td>42</td>\n      <td>United-States</td>\n      <td>43832</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>capital</th>\n      <td>48842.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>991.565313</td>\n      <td>7475.549906</td>\n      <td>-4356.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>99999.0</td>\n    </tr>\n    <tr>\n      <th>income</th>\n      <td>48842</td>\n      <td>2</td>\n      <td>&lt;=50K</td>\n      <td>37155</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "df = df.replace(\"?\",\"Other\")\n",
    "X = df.iloc[:, :-1]\n",
    "X_cols = X.columns\n",
    "y = df.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "X = ordinal_encoder.fit_transform(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=250, learning_rate=0.1, max_depth=4).fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8850357024031941"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8722489507626164"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "#creating Scoring parameter:\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1': make_scorer(precision_score)}\n",
    "\n",
    "# A sample parameter\n",
    "\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.05,0.1,0.2,0.5,1.0],\n",
    "    \"max_depth\":[2,3,4,5],\n",
    "    \"n_estimators\": np.linspace(100,500,7,dtype=int)\n",
    "}\n",
    "#passing the scoring function in the GridSearchCV\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=5, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "#converting the clf.cv_results to dataframe\n",
    "df=pd.DataFrame.from_dict(clf.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "     mean_test_accuracy  mean_test_f1\n0              0.843063      0.823440\n1              0.843063      0.823440\n2              0.856167      0.802526\n3              0.856167      0.802526\n4              0.860902      0.797506\n..                  ...           ...\n355            0.845392      0.687539\n356            0.844471      0.684936\n357            0.844650      0.685107\n358            0.842910      0.682428\n359            0.843985      0.683917\n\n[360 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_accuracy</th>\n      <th>mean_test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.843063</td>\n      <td>0.823440</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.843063</td>\n      <td>0.823440</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.856167</td>\n      <td>0.802526</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.856167</td>\n      <td>0.802526</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.860902</td>\n      <td>0.797506</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>0.845392</td>\n      <td>0.687539</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>0.844471</td>\n      <td>0.684936</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>0.844650</td>\n      <td>0.685107</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>0.842910</td>\n      <td>0.682428</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>0.843985</td>\n      <td>0.683917</td>\n    </tr>\n  </tbody>\n</table>\n<p>360 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['mean_test_accuracy','mean_test_f1']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 350, 'warm_start': True}"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['mean_test_accuracy'].idxmax()]['params']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Other'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-160-bd591573fef0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mclf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGradientBoostingClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlearning_rate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmax_depth\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m300\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mclf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mpreds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mpreds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[0;32m    410\u001B[0m         \u001B[1;31m# trees use different types for X and y, checking them separately.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 412\u001B[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001B[0m\u001B[0;32m    413\u001B[0m                                    dtype=DTYPE, multi_output=True)\n\u001B[0;32m    414\u001B[0m         \u001B[0mn_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_features_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    431\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    432\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 433\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    434\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    435\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y cannot be None\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 814\u001B[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001B[0m\u001B[0;32m    815\u001B[0m                     \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    816\u001B[0m                     \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    614\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"unsafe\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    615\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 616\u001B[1;33m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    617\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    618\u001B[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001B[0m in \u001B[0;36masarray\u001B[1;34m(a, dtype, order, like)\u001B[0m\n\u001B[0;32m    100\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_asarray_with_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlike\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlike\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1897\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1898\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1899\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1900\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1901\u001B[0m     def __array_wrap__(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001B[0m in \u001B[0;36masarray\u001B[1;34m(a, dtype, order, like)\u001B[0m\n\u001B[0;32m    100\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_asarray_with_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlike\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlike\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Other'"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.1,max_depth=4,n_estimators=300)\n",
    "clf.fit(X_train,y_train)\n",
    "preds = clf.predict(X_test)\n",
    "accuracy_score(y_test,preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, plot_roc_curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x16c4e615f10>"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(clf,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.94253028, 0.05746972],\n       [0.35314237, 0.64685763]])"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,preds,normalize='true')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "import catboost as cb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "model = cb.CatBoostClassifier(logging_level='Silent',eval_metric = 'Accuracy',cat_features=[1,3,4,5,6,7,8,10])\n",
    "\n",
    "grid = {'learning_rate': [0.05, 0.1,0.2,0.5,1.0],\n",
    "        'depth': [2, 3, 4, 5],\n",
    "        'n_estimators': [100]\n",
    "        }\n",
    "\n",
    "grid_search_result = model.grid_search(grid,\n",
    "                                       X=X_train,\n",
    "                                       y=y_train,\n",
    "                                       cv=5,\n",
    "                                       verbose=False\n",
    "                                       )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "{'params': {'depth': 3, 'iterations': 100, 'learning_rate': 1.0},\n 'cv_results': defaultdict(list,\n             {'iterations': [0,\n               1,\n               2,\n               3,\n               4,\n               5,\n               6,\n               7,\n               8,\n               9,\n               10,\n               11,\n               12,\n               13,\n               14,\n               15,\n               16,\n               17,\n               18,\n               19,\n               20,\n               21,\n               22,\n               23,\n               24,\n               25,\n               26,\n               27,\n               28,\n               29,\n               30,\n               31,\n               32,\n               33,\n               34,\n               35,\n               36,\n               37,\n               38,\n               39,\n               40,\n               41,\n               42,\n               43,\n               44,\n               45,\n               46,\n               47,\n               48,\n               49,\n               50,\n               51,\n               52,\n               53,\n               54,\n               55,\n               56,\n               57,\n               58,\n               59,\n               60,\n               61,\n               62,\n               63,\n               64,\n               65,\n               66,\n               67,\n               68,\n               69,\n               70,\n               71,\n               72,\n               73,\n               74,\n               75,\n               76,\n               77,\n               78,\n               79,\n               80,\n               81,\n               82,\n               83,\n               84,\n               85,\n               86,\n               87,\n               88,\n               89,\n               90,\n               91,\n               92,\n               93,\n               94,\n               95,\n               96,\n               97,\n               98,\n               99],\n              'test-Accuracy-mean': [0.8075146189206144,\n               0.8461853349492789,\n               0.8470299367524634,\n               0.8520460921151252,\n               0.8532489530660146,\n               0.8541959712385253,\n               0.8552708796865577,\n               0.8561922700220956,\n               0.8566529750152334,\n               0.858469990294173,\n               0.859314562621251,\n               0.8596216774491902,\n               0.8607733940803136,\n               0.8609782202687205,\n               0.8612596614079655,\n               0.861541272853603,\n               0.8627953141506108,\n               0.864586884999462,\n               0.8644588637190234,\n               0.865943247687231,\n               0.8665063035472365,\n               0.8665574937187236,\n               0.8670437839722362,\n               0.867862741562833,\n               0.867837172678073,\n               0.8674532463919199,\n               0.8674788840542617,\n               0.8677347890599758,\n               0.868041900612792,\n               0.8682978154438749,\n               0.8682722138078856,\n               0.8690399583011349,\n               0.8688352205410471,\n               0.868656071316457,\n               0.8688607992511759,\n               0.8688864041622881,\n               0.8688608189019135,\n               0.8694494796730314,\n               0.8688096058045659,\n               0.8686049040708305,\n               0.8688608352775283,\n               0.868732879499548,\n               0.8687328598488104,\n               0.8688352336415388,\n               0.8690399714016266,\n               0.8690144123422352,\n               0.86927034027381,\n               0.8695006665693954,\n               0.8696798125188627,\n               0.8696030174362633,\n               0.8692958895078325,\n               0.8694750485577915,\n               0.8704220307039499,\n               0.870370827431971,\n               0.8707802931267778,\n               0.8711897981230597,\n               0.8715736818326146,\n               0.8718552343260393,\n               0.8717528736338028,\n               0.8714969358768594,\n               0.8711130488921814,\n               0.8715993260452022,\n               0.8716761080273099,\n               0.871241037421391,\n               0.8713178390542362,\n               0.8714714324945578,\n               0.8715482046512969,\n               0.871241086548235,\n               0.871266652157872,\n               0.8715481620746987,\n               0.8713178292288675,\n               0.8714458046575849,\n               0.8709595111289496,\n               0.8708059537149803,\n               0.8712666456076261,\n               0.8713690128501085,\n               0.8710362931110573,\n               0.8710619143977842,\n               0.8707803750048513,\n               0.8709339291436977,\n               0.8710874800074215,\n               0.8712154456107705,\n               0.8714457817317246,\n               0.8714457751814786,\n               0.8706011799285402,\n               0.8703964356182065,\n               0.8708059209637508,\n               0.8709082849311102,\n               0.871113019416075,\n               0.8710618521704486,\n               0.8705243979464324,\n               0.8706779389847872,\n               0.8706779357096643,\n               0.8707291324313973,\n               0.8708059078632591,\n               0.8704220208785813,\n               0.8709850636380951,\n               0.8707547275171408,\n               0.8706523635497814,\n               0.8703964356182065],\n              'test-Accuracy-std': [0.00879182800860779,\n               0.0023429168246181364,\n               0.002348543491331312,\n               0.0030090335456876274,\n               0.0024154063447253673,\n               0.0022594482566482854,\n               0.0015828490911189161,\n               0.002308321520217177,\n               0.002709274647295364,\n               0.0037898927041079052,\n               0.0038950305283210933,\n               0.0020681598748078607,\n               0.0022224095045309234,\n               0.0029186172222405594,\n               0.0026685552422491023,\n               0.00342490019921268,\n               0.003392793450341097,\n               0.0031667101048795136,\n               0.002047630682222969,\n               0.0028727505226364483,\n               0.0024506064282835568,\n               0.0026401166736672674,\n               0.002699582856651365,\n               0.003748881280610209,\n               0.0030247059232862985,\n               0.0028793220875205305,\n               0.0027415661685318824,\n               0.002292823484715805,\n               0.0027387332947254694,\n               0.0026975589418305273,\n               0.0023392042166132635,\n               0.0032890137542749553,\n               0.003134950103798491,\n               0.002910832918495604,\n               0.003002876762061748,\n               0.002892791971144231,\n               0.0028406469529817313,\n               0.002712733988396034,\n               0.0034758788458042586,\n               0.002790292937785898,\n               0.0031134200994318677,\n               0.0029272374622875664,\n               0.002478561496959721,\n               0.0025430492074021835,\n               0.002668547791694298,\n               0.0027924107232322757,\n               0.0032680792814163647,\n               0.0029539700195007463,\n               0.0027552676651834457,\n               0.0027508624789200184,\n               0.0030648308101338412,\n               0.00313756116882397,\n               0.003255526693336674,\n               0.0032291114554979603,\n               0.003485589909526633,\n               0.0031805394771172234,\n               0.003761374669004098,\n               0.003148715658312797,\n               0.0034612523142241326,\n               0.0036671208635320482,\n               0.0037099881336027265,\n               0.0034526715199362673,\n               0.0032280690517735326,\n               0.0024965672433968915,\n               0.003404371559700682,\n               0.003151718942117129,\n               0.003218644218757058,\n               0.0030609168244309123,\n               0.0030497604100571942,\n               0.0032321627179060257,\n               0.0029639200974046548,\n               0.0030208728148255616,\n               0.0027970368448924175,\n               0.0023845841251354883,\n               0.002453593685478564,\n               0.0027902107053550075,\n               0.002723929780912056,\n               0.002727106683072824,\n               0.002741131871381829,\n               0.0023318560785885126,\n               0.002155448704992338,\n               0.0025615560401896975,\n               0.002746757731595555,\n               0.0026283456594700183,\n               0.00239302743080457,\n               0.002312971791997911,\n               0.002508874079253911,\n               0.0021025540113335695,\n               0.0022789753402674305,\n               0.0023747790479458643,\n               0.0027288687545043303,\n               0.0029158289357234177,\n               0.0029286217137860153,\n               0.0027189725859342036,\n               0.002784961563080718,\n               0.0031499634040791295,\n               0.0028354391601840643,\n               0.0026542777442853465,\n               0.002850673123794584,\n               0.002737703599761865],\n              'train-Accuracy-mean': [0.8078659121846336,\n               0.8456926567283116,\n               0.846345273688569,\n               0.8512783686396086,\n               0.8526604031685302,\n               0.8543495377867613,\n               0.8553796615858656,\n               0.8562498279719959,\n               0.856384194597845,\n               0.8578238066067725,\n               0.8588155379821856,\n               0.8597944912602262,\n               0.8609909593717603,\n               0.8619954798977328,\n               0.8629488225338509,\n               0.8637933850327835,\n               0.8651754166960643,\n               0.8660647789870071,\n               0.8666086411914697,\n               0.8677027531139174,\n               0.8681634333371109,\n               0.8683745743712216,\n               0.8686049143804739,\n               0.8694303041044098,\n               0.8696350477999439,\n               0.8702492819568765,\n               0.8706459769223678,\n               0.871055469430652,\n               0.8715545334806138,\n               0.8718552552673904,\n               0.8720152120662984,\n               0.8722711414298555,\n               0.8724630884013511,\n               0.8723927096941567,\n               0.8725462679263568,\n               0.8725910556417376,\n               0.8729109721051944,\n               0.8732884709611847,\n               0.8734484328773087,\n               0.8737363513900102,\n               0.8740306723585036,\n               0.8739219030698161,\n               0.8739730842346887,\n               0.8744017693727676,\n               0.8745361331329755,\n               0.8744849443946233,\n               0.874593717572395,\n               0.8745489239210439,\n               0.8749136260529953,\n               0.8750543867424023,\n               0.8750927769145184,\n               0.8749968027123602,\n               0.8751567560315614,\n               0.875233534942973,\n               0.8755726458784221,\n               0.8758477707374144,\n               0.8762380648846226,\n               0.8764748069402899,\n               0.8764684069407614,\n               0.8765771788904013,\n               0.8769418752910711,\n               0.8768842898282084,\n               0.8768331053883177,\n               0.8772362017861577,\n               0.8774473444577773,\n               0.8774793346303648,\n               0.8776968770968241,\n               0.8778632326671287,\n               0.8777608635826581,\n               0.8777928558021321,\n               0.877837640037806,\n               0.8778952212022071,\n               0.8780423802536335,\n               0.8782087378708244,\n               0.8783686948744212,\n               0.8785606404130963,\n               0.8785542432792088,\n               0.878637418710442,\n               0.8787269959834012,\n               0.878835767933041,\n               0.8787461961866748,\n               0.8788293701850876,\n               0.8788357669095979,\n               0.8788933509396399,\n               0.8789573345598332,\n               0.8790661022110117,\n               0.879264451842988,\n               0.8792004694509264,\n               0.8792260606474288,\n               0.8794052139652152,\n               0.8795459728124244,\n               0.8796163539758826,\n               0.8795971601179563,\n               0.8796803367773212,\n               0.8797251287911634,\n               0.879891485998977,\n               0.8798275021740952,\n               0.8798658896852588,\n               0.8799682636822567,\n               0.8800514405463101],\n              'train-Accuracy-std': [0.009532427253601216,\n               0.0016013978418568402,\n               0.0022232744984674252,\n               0.0014222502064593543,\n               0.00143210645609967,\n               0.0016008073331133992,\n               0.0010523941879684482,\n               0.0012371736088654173,\n               0.0009271797423568031,\n               0.0011727374123383886,\n               0.0013889526640675834,\n               0.001976866674983342,\n               0.0020643407612014326,\n               0.0020605294433829312,\n               0.0019228553561369624,\n               0.0027272378984488136,\n               0.002268968796377878,\n               0.0027956962111978898,\n               0.0028565923647757134,\n               0.0019501860921622444,\n               0.0014276328354176939,\n               0.0013713205128439395,\n               0.001534661332024898,\n               0.0013614603733856643,\n               0.0015281402081022545,\n               0.0014069541253787284,\n               0.001724952716518024,\n               0.0022071794338301824,\n               0.001927936232671863,\n               0.0022323680764874364,\n               0.002417600519111652,\n               0.002211791484350179,\n               0.0020915552911199686,\n               0.0020549403752314456,\n               0.002038427122495195,\n               0.002063843970921663,\n               0.0020443463498343176,\n               0.002080770228454945,\n               0.002039902199957956,\n               0.0017312727194993744,\n               0.0015962708340293375,\n               0.0016507196129996848,\n               0.0014554545245853857,\n               0.0014457850994071444,\n               0.0016056860572774313,\n               0.0017750289796632087,\n               0.0015662635565335081,\n               0.001702628201733762,\n               0.001636003351578931,\n               0.0016922049452412255,\n               0.0016467922785883217,\n               0.0017433973440454705,\n               0.0017249939202556117,\n               0.0017432414422337474,\n               0.001604332354644193,\n               0.0017056797211902489,\n               0.0017872500616008798,\n               0.001923416916721455,\n               0.001924247203152162,\n               0.0018507306558309894,\n               0.001732028653996913,\n               0.0016022748264522514,\n               0.0016088595624570339,\n               0.0013817467022245635,\n               0.0013256365307080598,\n               0.0013896651936167674,\n               0.0013375072067668453,\n               0.0012951766805794223,\n               0.0012753810644254733,\n               0.0012627815950904007,\n               0.0012454062270319379,\n               0.001319196997554709,\n               0.0012733691834279153,\n               0.00159346174805366,\n               0.0015059529440220817,\n               0.0015269920911505663,\n               0.0014527531138661765,\n               0.0014817891458249834,\n               0.0014539006186276339,\n               0.0012569116006718964,\n               0.0012164280280882657,\n               0.0011317302395781278,\n               0.0011056380521776846,\n               0.00115194490843184,\n               0.0011718776137077266,\n               0.0012203584022815296,\n               0.0012388503709872504,\n               0.0013470515094731656,\n               0.001349998475426336,\n               0.0016127649327034607,\n               0.0015091263080788215,\n               0.001545736002155258,\n               0.0017077469584417244,\n               0.001568250892920899,\n               0.0014925520492515706,\n               0.0013239156827128612,\n               0.0011801669855522365,\n               0.0013004512213745495,\n               0.001362842492801946,\n               0.001357209844925603],\n              'test-Logloss-mean': [0.3884236258014483,\n               0.3460178628397085,\n               0.3307915450982983,\n               0.3215922106943666,\n               0.3173945651125009,\n               0.31479213667941786,\n               0.3130589159542451,\n               0.3116259106157651,\n               0.3107931964468328,\n               0.3091316265698981,\n               0.30786904714586494,\n               0.30585994103718733,\n               0.30319332177858993,\n               0.3013338597691829,\n               0.30050434500003365,\n               0.298590719577743,\n               0.29630786844908835,\n               0.29504003027805237,\n               0.2932949295854308,\n               0.29113927963200187,\n               0.2902035500732033,\n               0.28983032957040933,\n               0.2891979915330388,\n               0.2879810077362337,\n               0.2877790506509082,\n               0.28719658922625496,\n               0.28710438730279486,\n               0.28592959764926706,\n               0.2853669168720335,\n               0.2849792843903039,\n               0.2851542226955129,\n               0.2847952153606552,\n               0.28442915456678997,\n               0.28453052638021115,\n               0.2845119036294105,\n               0.2841268484153913,\n               0.2841034837176365,\n               0.2833747546236525,\n               0.2827164494613779,\n               0.28238763974448877,\n               0.2826255456804919,\n               0.2827305890097517,\n               0.282830146367251,\n               0.28269844680050743,\n               0.2826329246945522,\n               0.28274724588610745,\n               0.28266164583796943,\n               0.2825627835944844,\n               0.2825675306031644,\n               0.2826177557892509,\n               0.28262628519710564,\n               0.2824697469210111,\n               0.28263956247188515,\n               0.28228209713492836,\n               0.28237256508129266,\n               0.28206690913056354,\n               0.28153963086715345,\n               0.28117871337712474,\n               0.28126420846454214,\n               0.2813929888704704,\n               0.2812647516291338,\n               0.281183246462391,\n               0.2811249982062799,\n               0.2810093547638989,\n               0.2806941894872227,\n               0.28074890358517895,\n               0.2803424830486517,\n               0.2802729393065489,\n               0.28044141451918214,\n               0.2805987568646452,\n               0.28076114288561443,\n               0.2808049543708381,\n               0.28092103177316463,\n               0.2808533673152644,\n               0.28092634668743943,\n               0.2810227933986136,\n               0.28106342968882175,\n               0.28101252105164753,\n               0.28093445482830187,\n               0.280755885159447,\n               0.28085921723261525,\n               0.28109256158169693,\n               0.2810864822439289,\n               0.2810175841681432,\n               0.2811918190028428,\n               0.2812498966888034,\n               0.28100849740212075,\n               0.2810856183848551,\n               0.2810565470099129,\n               0.28103801171110615,\n               0.28103807597545927,\n               0.28083623224801413,\n               0.280911271320997,\n               0.28100211870849406,\n               0.2810003706727491,\n               0.2809712260226917,\n               0.28088095780447503,\n               0.28086891234249667,\n               0.2809160605042933,\n               0.2810906954470453],\n              'test-Logloss-std': [0.00550395689389933,\n               0.00775567410791013,\n               0.0063715821951477545,\n               0.006437852503342559,\n               0.0060064431104472175,\n               0.006203996337003134,\n               0.006954761358541873,\n               0.007180724282261541,\n               0.006697032535335943,\n               0.00678442873220564,\n               0.006172122005955036,\n               0.006652048390014824,\n               0.007753131836842935,\n               0.007657019413720257,\n               0.007412142837766537,\n               0.007446157348708404,\n               0.008172886583613013,\n               0.007527637064129428,\n               0.007328586362326557,\n               0.008072510763541476,\n               0.00761398750809498,\n               0.007426800452919924,\n               0.007156499110933364,\n               0.0073143746265605675,\n               0.007206387008699829,\n               0.007671208329313375,\n               0.00787827749298263,\n               0.007566978376394027,\n               0.007408803120827426,\n               0.007810130204498362,\n               0.007919108335148577,\n               0.00817613331704367,\n               0.008357470146686924,\n               0.008317481474095166,\n               0.008439323609994002,\n               0.00841590838222574,\n               0.008306078549462624,\n               0.007862248555434994,\n               0.007846046373495494,\n               0.007420516604674454,\n               0.007288719034353365,\n               0.007455671726711694,\n               0.007577464820377012,\n               0.0077084057925052565,\n               0.007679354764839389,\n               0.007819807629882644,\n               0.0078170848558943,\n               0.00785201592792395,\n               0.00794602702076834,\n               0.007931971615860447,\n               0.007825189924134486,\n               0.007815480210744494,\n               0.007845672401457544,\n               0.0076628944438159735,\n               0.00802520511455222,\n               0.008321383554566488,\n               0.008658376499134564,\n               0.00838992967875132,\n               0.008415492758494986,\n               0.008612466757825612,\n               0.008538461489858273,\n               0.00846250058389306,\n               0.008640595736751022,\n               0.00810186014133102,\n               0.007705220629141165,\n               0.007397297293454862,\n               0.007399080505505106,\n               0.007383283261405942,\n               0.007471291340854852,\n               0.0074559384989151154,\n               0.007524278332277403,\n               0.007628541554815289,\n               0.007650428726888505,\n               0.007621304643333719,\n               0.007032113237733645,\n               0.007161087912613301,\n               0.007273636706104511,\n               0.007287440305651878,\n               0.007359884853569584,\n               0.00725237496069171,\n               0.007080345657295805,\n               0.007144430901745697,\n               0.0071324682797957555,\n               0.007073567134721995,\n               0.007165019614561648,\n               0.0069392998308721926,\n               0.007166118344684172,\n               0.0071881118825810235,\n               0.007207056904305241,\n               0.007265175054557079,\n               0.007582086166606683,\n               0.008019373568537025,\n               0.008063536422120458,\n               0.008079281017389433,\n               0.008010705246429483,\n               0.007948532917468045,\n               0.007905649723102485,\n               0.00803460263852253,\n               0.008115584514722236,\n               0.008070120695677816],\n              'train-Logloss-mean': [0.3887664264581593,\n               0.3472269922273701,\n               0.3313297065686117,\n               0.3217779637453319,\n               0.3169902188622665,\n               0.3144590597413141,\n               0.3126349822712247,\n               0.31107641132541614,\n               0.3097952126513822,\n               0.3079506297815478,\n               0.30643602341291054,\n               0.30414216579760234,\n               0.30108656229405106,\n               0.29889846558413663,\n               0.2975782699837403,\n               0.29508994942904565,\n               0.29313336984691946,\n               0.29163005007248605,\n               0.28938848400448614,\n               0.2873279080191466,\n               0.2859060771008803,\n               0.2853668997763195,\n               0.2847525278748614,\n               0.28368867782851515,\n               0.28308582487652706,\n               0.28237657308665254,\n               0.28171534272499626,\n               0.2803764583671223,\n               0.279649097126001,\n               0.2792031885601597,\n               0.2790162368254751,\n               0.27876767313551953,\n               0.2782822212395022,\n               0.27811329558675163,\n               0.27783384590031435,\n               0.2773981016885605,\n               0.27705991737037317,\n               0.27637957270146896,\n               0.2757835127576837,\n               0.2752301805155917,\n               0.2750147493573664,\n               0.27471902638755824,\n               0.27441275876974874,\n               0.2739224323030028,\n               0.2735898225337751,\n               0.2733452651865256,\n               0.27318797805113615,\n               0.2730273304711308,\n               0.27280509735260655,\n               0.2724368381643682,\n               0.27229309985902056,\n               0.2719979097633821,\n               0.2717574124601859,\n               0.2715155947151131,\n               0.27117397571404983,\n               0.27062694712377955,\n               0.26987684037443527,\n               0.269437352793506,\n               0.26928551462566014,\n               0.2691043617469095,\n               0.26892968200698925,\n               0.2687586843091264,\n               0.2685469471610762,\n               0.268071872492445,\n               0.26767247216707973,\n               0.2675643364860152,\n               0.26721519442999064,\n               0.26712169469573954,\n               0.2669847899683562,\n               0.26680587106209686,\n               0.2666778541172044,\n               0.2664908718435363,\n               0.2663764101403835,\n               0.2661286468049783,\n               0.26586802011498045,\n               0.26568604230923015,\n               0.2655309447697647,\n               0.26541891725856154,\n               0.2652659072708509,\n               0.26511005273318045,\n               0.26495525933346686,\n               0.2647570564544133,\n               0.26464721334746166,\n               0.26452360083859894,\n               0.2643051432238427,\n               0.2641721007117342,\n               0.2639935588417709,\n               0.2638554263244563,\n               0.26373130657607047,\n               0.2636029993098511,\n               0.2634057591690209,\n               0.2631814773544829,\n               0.26305861959116567,\n               0.2629185004158823,\n               0.26283797236891804,\n               0.2627011632766133,\n               0.2626182783143693,\n               0.26252229328156634,\n               0.2624366529147327,\n               0.2622868350395243],\n              'train-Logloss-std': [0.008168916617096256,\n               0.008929541004242585,\n               0.00520344118847371,\n               0.0030797643915768023,\n               0.0030185919473205754,\n               0.003355795502613524,\n               0.002711186588404814,\n               0.0023756929627821314,\n               0.002612959785132885,\n               0.002868078000001946,\n               0.0030451145463078633,\n               0.002614574598374291,\n               0.002529989610655017,\n               0.003953198645801757,\n               0.0039581261344485506,\n               0.005193343319127329,\n               0.0051031789814874485,\n               0.005219026964029711,\n               0.004971511482583412,\n               0.0036412499922307703,\n               0.002416240490627639,\n               0.0024309096413931497,\n               0.002323670713240298,\n               0.0014205204752116686,\n               0.0015726811611441827,\n               0.0014256211888381695,\n               0.0015982636271059819,\n               0.0019966606174567033,\n               0.001670744115402961,\n               0.0017770629555148455,\n               0.001892410445780315,\n               0.0017812529003500446,\n               0.0018339231645169048,\n               0.0018059656045834374,\n               0.0018087819785356368,\n               0.00175567066973347,\n               0.001701462213760123,\n               0.0016343982022160935,\n               0.0014870972438466134,\n               0.001613692882453459,\n               0.0014823449903632725,\n               0.0013924240329412775,\n               0.0014650807697151312,\n               0.0014940926977145745,\n               0.001583263687702249,\n               0.001714715396068098,\n               0.0016487865756251298,\n               0.001631034887445787,\n               0.0015587145598629116,\n               0.0017487981133888397,\n               0.0016881169817261838,\n               0.0015731729406622504,\n               0.0015205215594361278,\n               0.0014565820827217985,\n               0.0013438371770238084,\n               0.00128960303681375,\n               0.0011275972946425993,\n               0.0014798328997136815,\n               0.001506495101202263,\n               0.0015299475631499217,\n               0.0015561813878994012,\n               0.001536991498015912,\n               0.0014182159610397935,\n               0.0015205365939593323,\n               0.001569436372568049,\n               0.0015254340787739116,\n               0.0013754763859374032,\n               0.0013800927080202267,\n               0.001392349380925269,\n               0.0013011761998956055,\n               0.0013295841632396735,\n               0.0013355393812567499,\n               0.001308791507527023,\n               0.00136226672054706,\n               0.0013210110475815218,\n               0.0013719922311035777,\n               0.0014042357829419775,\n               0.00135941418851489,\n               0.0014115528382029824,\n               0.0015311263504263874,\n               0.0014427146349481382,\n               0.001486918071495201,\n               0.0014644146199049935,\n               0.0015834203651399134,\n               0.001642515776956377,\n               0.0015714799830424105,\n               0.0015037974815744098,\n               0.001523008676735693,\n               0.0015392183458021707,\n               0.0015283125764864842,\n               0.0016255452743025038,\n               0.001429312396840314,\n               0.0014245036975458142,\n               0.0014294813506322357,\n               0.0014311728814560966,\n               0.0014545241669414253,\n               0.0014575175469754011,\n               0.0015125031503200634,\n               0.00151988987244046,\n               0.0014368861330607593]})}"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}